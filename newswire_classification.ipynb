{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jacob\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\reuters.py:148: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\jacob\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\reuters.py:149: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = keras.datasets.reuters.load_data(num_words = 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8982"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2246"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutate Data as Needed (Vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequence(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequence(train_data)\n",
    "x_test = vectorize_sequence(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(labels, dimension=46):\n",
    "    results = np.zeros((len(labels), dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1\n",
    "    return results\n",
    "\n",
    "one_hot_train_labels = one_hot_encoding(train_labels)\n",
    "one_hot_test_labels = one_hot_encoding(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(46, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss = 'categorical_crossentropy',\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.0841 - accuracy: 0.9608 - val_loss: 1.2864 - val_accuracy: 0.7960\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0857 - accuracy: 0.9612 - val_loss: 1.4403 - val_accuracy: 0.7750\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.0854 - accuracy: 0.9595 - val_loss: 1.3969 - val_accuracy: 0.7810\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0877 - accuracy: 0.9574 - val_loss: 1.3194 - val_accuracy: 0.7960\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.0861 - accuracy: 0.9588 - val_loss: 1.3670 - val_accuracy: 0.7800\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0828 - accuracy: 0.9588 - val_loss: 1.3612 - val_accuracy: 0.7990\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0810 - accuracy: 0.9607 - val_loss: 1.4259 - val_accuracy: 0.7790\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.0857 - accuracy: 0.9583 - val_loss: 1.3654 - val_accuracy: 0.7920\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 1s 39ms/step - loss: 0.0857 - accuracy: 0.9575 - val_loss: 1.3541 - val_accuracy: 0.7920\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.0841 - accuracy: 0.9584 - val_loss: 1.4196 - val_accuracy: 0.7890\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.0830 - accuracy: 0.9584 - val_loss: 1.4036 - val_accuracy: 0.7810\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.0802 - accuracy: 0.9587 - val_loss: 1.4525 - val_accuracy: 0.7840\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.0787 - accuracy: 0.9620 - val_loss: 1.4646 - val_accuracy: 0.7720\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 1s 41ms/step - loss: 0.0801 - accuracy: 0.9607 - val_loss: 1.4602 - val_accuracy: 0.7780\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.0791 - accuracy: 0.9598 - val_loss: 1.4850 - val_accuracy: 0.7830\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0799 - accuracy: 0.9592 - val_loss: 1.4707 - val_accuracy: 0.7850\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.0799 - accuracy: 0.9595 - val_loss: 1.4365 - val_accuracy: 0.7880\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.0775 - accuracy: 0.9605 - val_loss: 1.4967 - val_accuracy: 0.7880\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.0772 - accuracy: 0.9589 - val_loss: 1.4709 - val_accuracy: 0.7860\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.0764 - accuracy: 0.9612 - val_loss: 1.4405 - val_accuracy: 0.7890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs = 20,\n",
    "                    batch_size = 512,\n",
    "                    validation_data =(x_val, y_val))\n",
    "\n",
    "history.history.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-1f197220147a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bo'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Training acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Validation acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training and validation accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
